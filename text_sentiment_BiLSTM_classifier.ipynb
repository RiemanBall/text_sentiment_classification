{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r67y9UpchZ38"
   },
   "source": [
    "# Recurrent Neural Networks for text sentiment classification\n",
    "\n",
    "Given a sentence, we are going to classify whether this sentence has negative meaning. Negative meaning will have label == 1, positive meaning will have label == 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zxMj1LNnAsDf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import w2v\n",
    "from utils import *\n",
    "from preprocess import Preprocess\n",
    "from model import buildModel, testing, BiLstmTuner\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1217,
     "status": "ok",
     "timestamp": 1604897610868,
     "user": {
      "displayName": "Meng-Hao Li",
      "photoUrl": "",
      "userId": "12054031135643111000"
     },
     "user_tz": 480
    },
    "id": "SkOXr7KDsBJn",
    "outputId": "fd9cd6ad-8370-485f-dac6-d1eda6736b12"
   },
   "outputs": [],
   "source": [
    "path_prefix = Path.cwd()\n",
    "print(path_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1217,
     "status": "ok",
     "timestamp": 1604897610868,
     "user": {
      "displayName": "Meng-Hao Li",
      "photoUrl": "",
      "userId": "12054031135643111000"
     },
     "user_tz": 480
    },
    "id": "SkOXr7KDsBJn",
    "outputId": "fd9cd6ad-8370-485f-dac6-d1eda6736b12"
   },
   "outputs": [],
   "source": [
    "data_path = path_prefix.joinpath('data/')\n",
    "model_path = path_prefix.joinpath('model/')\n",
    "data_path.mkdir(exist_ok = True)\n",
    "model_path.mkdir(exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YrAlczfM_w6"
   },
   "source": [
    "## Download Dataset\n",
    "[Dataset](https://www.kaggle.com/c/ml2020spring-hw4)\n",
    "\n",
    "There are three .txt files -- training_label.txt、training_nolabel.txt、testing_data.txt\n",
    "\n",
    "- training_label.txt: training data with labels（0 or 1)\n",
    "    - +++$+++ is separating symbols\n",
    "    - e.g., 1 +++$+++ are wtf ... awww thanks !\n",
    "\n",
    "- training_nolabel.txt：training data without labels\n",
    "    - We will use this training data for semi-supervised learning\n",
    "    - ex: hates being this burnt !! ouch\n",
    "\n",
    "- testing_data.txt： Predict with testing data \n",
    "\n",
    "    >id,text\n",
    "\n",
    "    >0,my dog ate our dinner . no , seriously ... he ate it .\n",
    "\n",
    "    >1,omg last day sooon n of primary noooooo x im gona be swimming out of school wif the amount of tears am gona cry\n",
    "\n",
    "    >2,stupid boys .. they ' re so .. stupid !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSyhKF2iwrcl"
   },
   "source": [
    "### Download dataset if not have any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 886,
     "status": "ok",
     "timestamp": 1604897685825,
     "user": {
      "displayName": "Meng-Hao Li",
      "photoUrl": "",
      "userId": "12054031135643111000"
     },
     "user_tz": 480
    },
    "id": "x2gwKORmuViJ",
    "outputId": "be82d0fa-44d0-4b70-ab15-9c400a39a84f"
   },
   "outputs": [],
   "source": [
    "%cd $data_path\n",
    "\n",
    "if not os.path.exists('training_label.txt') or\\\n",
    "    not os.path.exists('training_nolabel.txt') or\\\n",
    "    not os.path.exists('testing_data.txt'):\n",
    "    print(\"Dataset is incompleted . Downloading\")\n",
    "    # Method1\n",
    "    !wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1dPHIl8ZnfDz_fxNd2ZeBYedTat2lfxcO' -O 'training_label.txt'\n",
    "    !wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1x1rJOX_ETqnOZjdMAbEE2pqIjRNa8xcc' -O 'training_nolabel.txt'\n",
    "    !wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=16CtnQwSDCob9xmm6EdHHR7PNFNiOrQ30' -O 'testing_data.txt'\n",
    "\n",
    "    # Method2\n",
    "    # !gdown --id '1lz0Wtwxsh5YCPdqQ3E3l_nbfJT1N13V8' --output data.zip\n",
    "    # !unzip data.zip\n",
    "    # !ls\n",
    "else:\n",
    "    print(\"data is all set\")\n",
    "   \n",
    "%cd $path_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8hDIokoP6464"
   },
   "outputs": [],
   "source": [
    "# this is for filtering the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYE8UYQsNIxM"
   },
   "source": [
    "## Train Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cgGWaF8_2S3q"
   },
   "outputs": [],
   "source": [
    "w2v_path = path_prefix.joinpath('model/w2v_all.model') \n",
    "\n",
    "if not w2v_path.exists():\n",
    "    print(\"Train Word2Vec model via gensim\")\n",
    "    data_folder_path = './data'\n",
    "    model_folder_path = './model'\n",
    "\n",
    "    w2v.main(data_folder_path, model_folder_path)\n",
    "else:\n",
    "    print(\"Pretrained Word2Vec model exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup paths and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EztIWqCmlZof"
   },
   "outputs": [],
   "source": [
    "# Preset the paths to dataset\n",
    "train_with_label = os.path.join(path_prefix, 'data/training_label.txt')\n",
    "train_no_label = os.path.join(path_prefix, 'data/training_nolabel.txt')\n",
    "testing_data = os.path.join(path_prefix, 'data/testing_data.txt')\n",
    "\n",
    "# Configuration\n",
    "sen_len = 20\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EztIWqCmlZof"
   },
   "outputs": [],
   "source": [
    "# Read 'training_label.txt' and 'training_nolabel.txt'\n",
    "print(\"loading training data ...\")\n",
    "X_train_lable, y_train_lable = load_training_data(train_with_label)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_lable, \n",
    "                                                  y_train_lable, \n",
    "                                                  test_size = 0.1)\n",
    "\n",
    "train_x_no_label = load_training_data(train_no_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Positive rate in training dataset: {np.sum(y_train) / len(y_train)}\")\n",
    "print(f\"Positive rate in validation dataset: {np.sum(y_val) / len(y_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EztIWqCmlZof"
   },
   "outputs": [],
   "source": [
    "# Preprocess the training data\n",
    "preprocessor = Preprocess(sen_len, w2v_path = str(w2v_path))\n",
    "embedding = preprocessor.make_embedding(load = True)\n",
    "X_train_idx = preprocessor.sentences_word2idx(X_train)\n",
    "X_val_idx = preprocessor.sentences_word2idx(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Pretrained embedding matrix shape: {embedding.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EztIWqCmlZof"
   },
   "outputs": [],
   "source": [
    "X_train_idx_dataset = tf.data.Dataset.from_tensor_slices(X_train_idx)\n",
    "y_train_dataset = tf.data.Dataset.from_tensor_slices(y_train)\n",
    "train_dataset = tf.data.Dataset.zip((X_train_idx_dataset, y_train_dataset))\n",
    "\n",
    "X_val_idx_dataset = tf.data.Dataset.from_tensor_slices(X_val_idx)\n",
    "y_val_dataset = tf.data.Dataset.from_tensor_slices(y_val)\n",
    "val_dataset = tf.data.Dataset.zip((X_val_idx_dataset, y_val_dataset))\n",
    "\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "val_dataset   = val_dataset.batch(batch_size)\n",
    "\n",
    "train_dataset = train_dataset.cache().prefetch(AUTOTUNE)\n",
    "val_dataset   = val_dataset.cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_batch, y_batch in train_dataset.take(1):\n",
    "    print(f\"x_batch shape: {x_batch.shape}\")\n",
    "    print(f\"y_batch shape: {y_batch.shape}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a bidirectional LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedding = False # fix embedding during training\n",
    "hidden_dim1 = 64\n",
    "hidden_dim2 = 64\n",
    "dp_rate = 0.5\n",
    "lr = 0.001\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EztIWqCmlZof"
   },
   "outputs": [],
   "source": [
    "model = buildModel(embedding, train_embedding, sen_len, hidden_dim1, hidden_dim2, dp_rate, lr)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = os.path.join(path_prefix, 'ckpt/')\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, \n",
    "                      validation_data=val_dataset, \n",
    "                      epochs = epochs, \n",
    "                      callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method2 - with Kerastuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(*args, **kwargs):\n",
    "        IPython.display.clear_output(wait = True)\n",
    "    \n",
    "tuner = RandomSearch(\n",
    "    BiLstmTuner(embedding, train_embedding, sen_len),\n",
    "    objective='val_accuracy',\n",
    "    max_trials = 10,\n",
    "    executions_per_trial = 3,\n",
    "    directory = os.path.join(path_prefix, 'tuner_dir'),\n",
    "    project_name = 'tsc')\n",
    "\n",
    "tuner.search(train_dataset,\n",
    "             epochs = 5,\n",
    "             validation_data = val_dataset,\n",
    "             verbose = 0,\n",
    "             callbacks = [ClearTrainingOutput()],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fQeaQNeNm3L"
   },
   "source": [
    "### Preprocess test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFvjFQopxVrt"
   },
   "outputs": [],
   "source": [
    "print(\"loading testing data ...\")\n",
    "X_test = load_testing_data(testing_data)\n",
    "X_test_idx = preprocessor.sentences_word2idx(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices(X_test_idx)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFvjFQopxVrt"
   },
   "outputs": [],
   "source": [
    "print('\\nload model ...')\n",
    "best_model = tf.keras.models.load_model(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_model = tuner.get_best_models()[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = testing(best_model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFvjFQopxVrt"
   },
   "outputs": [],
   "source": [
    "# Write the result to a CSV file\n",
    "tmp = pd.DataFrame({\"id\":[str(i) for i in range(len(X_test))],\"label\":outputs})\n",
    "print(\"save csv ...\")\n",
    "tmp.to_csv(os.path.join(path_prefix, 'predict.csv'), index=False)\n",
    "print(\"Finish Predicting\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW4_RNN.ipynb",
   "provenance": [
    {
     "file_id": "16d1Xox0OW-VNuxDn1pvy2UXFIPfieCb9",
     "timestamp": 1604814490480
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
