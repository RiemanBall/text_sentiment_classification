{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r67y9UpchZ38"
   },
   "source": [
    "# Recurrent Neural Networks for text sentiment classification\n",
    "\n",
    "In this notebook, we will use the Twitter dataset for sentiment classificatoin using Bi-LSTM. Given a sentence, we are going to classify whether this sentence has negative meaning. Negative meaning will have label == 0, otherwise will have label == 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zxMj1LNnAsDf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import w2v\n",
    "from utils import *\n",
    "from preprocess import Preprocess\n",
    "from model import buildModel, testing, BiLstmTuner\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1217,
     "status": "ok",
     "timestamp": 1604897610868,
     "user": {
      "displayName": "Meng-Hao Li",
      "photoUrl": "",
      "userId": "12054031135643111000"
     },
     "user_tz": 480
    },
    "id": "SkOXr7KDsBJn",
    "outputId": "fd9cd6ad-8370-485f-dac6-d1eda6736b12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/meng-hao/wkspaces/Machine_Learning/repos/text_sentiment_classification\n"
     ]
    }
   ],
   "source": [
    "path_prefix = Path.cwd()\n",
    "print(path_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1217,
     "status": "ok",
     "timestamp": 1604897610868,
     "user": {
      "displayName": "Meng-Hao Li",
      "photoUrl": "",
      "userId": "12054031135643111000"
     },
     "user_tz": 480
    },
    "id": "SkOXr7KDsBJn",
    "outputId": "fd9cd6ad-8370-485f-dac6-d1eda6736b12"
   },
   "outputs": [],
   "source": [
    "data_path = path_prefix.joinpath('data/')\n",
    "model_path = path_prefix.joinpath('model/')\n",
    "data_path.mkdir(exist_ok = True)\n",
    "model_path.mkdir(exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YrAlczfM_w6"
   },
   "source": [
    "## Download Dataset\n",
    "[Dataset](https://www.kaggle.com/c/ml2020spring-hw4)\n",
    "\n",
    "There are three .txt files -- training_label.txt、training_nolabel.txt、testing_data.txt\n",
    "\n",
    "- training_label.txt: training data with labels（0 or 1)\n",
    "    - +++$+++ is separating symbols\n",
    "    - e.g., 1 +++$+++ are wtf ... awww thanks !\n",
    "\n",
    "- training_nolabel.txt：training data without labels\n",
    "    - We will use this training data for semi-supervised learning\n",
    "    - ex: hates being this burnt !! ouch\n",
    "\n",
    "- testing_data.txt： Predict with testing data \n",
    "\n",
    "    >id,text\n",
    "\n",
    "    >0,my dog ate our dinner . no , seriously ... he ate it .\n",
    "\n",
    "    >1,omg last day sooon n of primary noooooo x im gona be swimming out of school wif the amount of tears am gona cry\n",
    "\n",
    "    >2,stupid boys .. they ' re so .. stupid !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSyhKF2iwrcl"
   },
   "source": [
    "### Download dataset if not have any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 886,
     "status": "ok",
     "timestamp": 1604897685825,
     "user": {
      "displayName": "Meng-Hao Li",
      "photoUrl": "",
      "userId": "12054031135643111000"
     },
     "user_tz": 480
    },
    "id": "x2gwKORmuViJ",
    "outputId": "be82d0fa-44d0-4b70-ab15-9c400a39a84f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/meng-hao/wkspaces/Machine_Learning/repos/text_sentiment_classification/data\n",
      "data is all set\n",
      "/home/meng-hao/wkspaces/Machine_Learning/repos/text_sentiment_classification\n"
     ]
    }
   ],
   "source": [
    "%cd $data_path\n",
    "\n",
    "if not os.path.exists('training_label.txt') or\\\n",
    "    not os.path.exists('training_nolabel.txt') or\\\n",
    "    not os.path.exists('testing_data.txt'):\n",
    "    print(\"Dataset is incompleted . Downloading\")\n",
    "    # Method1\n",
    "    !wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1dPHIl8ZnfDz_fxNd2ZeBYedTat2lfxcO' -O 'training_label.txt'\n",
    "    !wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1x1rJOX_ETqnOZjdMAbEE2pqIjRNa8xcc' -O 'training_nolabel.txt'\n",
    "    !wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=16CtnQwSDCob9xmm6EdHHR7PNFNiOrQ30' -O 'testing_data.txt'\n",
    "\n",
    "    # Method2\n",
    "    # !gdown --id '1lz0Wtwxsh5YCPdqQ3E3l_nbfJT1N13V8' --output data.zip\n",
    "    # !unzip data.zip\n",
    "    # !ls\n",
    "else:\n",
    "    print(\"data is all set\")\n",
    "   \n",
    "%cd $path_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8hDIokoP6464"
   },
   "outputs": [],
   "source": [
    "# this is for filtering the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYE8UYQsNIxM"
   },
   "source": [
    "## Train Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cgGWaF8_2S3q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained Word2Vec model exists\n"
     ]
    }
   ],
   "source": [
    "w2v_path = path_prefix.joinpath('model/w2v_all.model') \n",
    "\n",
    "if not w2v_path.exists():\n",
    "    print(\"Train Word2Vec model via gensim\")\n",
    "    data_folder_path = './data'\n",
    "    model_folder_path = './model'\n",
    "\n",
    "    w2v.main(data_folder_path, model_folder_path)\n",
    "else:\n",
    "    print(\"Pretrained Word2Vec model exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup paths and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EztIWqCmlZof"
   },
   "outputs": [],
   "source": [
    "# Preset the paths to dataset\n",
    "train_with_label = os.path.join(path_prefix, 'data/training_label.txt')\n",
    "train_no_label = os.path.join(path_prefix, 'data/training_nolabel.txt')\n",
    "testing_data = os.path.join(path_prefix, 'data/testing_data.txt')\n",
    "\n",
    "# Configuration\n",
    "sen_len = 20\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EztIWqCmlZof"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training data ...\n"
     ]
    }
   ],
   "source": [
    "# Read 'training_label.txt' and 'training_nolabel.txt'\n",
    "print(\"loading training data ...\")\n",
    "X_train_label, y_train_label = load_training_data(train_with_label)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_label, \n",
    "                                                  y_train_label, \n",
    "                                                  test_size = 0.1)\n",
    "\n",
    "train_x_no_label = load_training_data(train_no_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of the training data with label: 180000\n",
      "Total number of the training data without label: 1178614\n",
      "Total number of the validation data: 20000\n",
      "Positive rate in training dataset: 0.5007222222222222\n",
      "Positive rate in validation dataset: 0.49575\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of the training data with label: {len(X_train)}\")\n",
    "print(f\"Total number of the training data without label: {len(train_x_no_label)}\")\n",
    "print(f\"Total number of the validation data: {len(X_val)}\")\n",
    "\n",
    "print(f\"Positive rate in training dataset: {np.sum(y_train) / len(y_train)}\")\n",
    "print(f\"Positive rate in validation dataset: {np.sum(y_val) / len(y_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EztIWqCmlZof"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get embedding ...\n",
      "loading word to vec model ...\n",
      "total words: 55779\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the training data\n",
    "preprocessor = Preprocess(sen_len, w2v_path = str(w2v_path))\n",
    "embedding = preprocessor.make_embedding(load = True)\n",
    "X_train_idx = preprocessor.sentences_word2idx(X_train)\n",
    "X_val_idx = preprocessor.sentences_word2idx(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained embedding matrix shape: (55779, 250)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Pretrained embedding matrix shape: {embedding.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "EztIWqCmlZof"
   },
   "outputs": [],
   "source": [
    "X_train_idx_dataset = tf.data.Dataset.from_tensor_slices(X_train_idx)\n",
    "y_train_dataset = tf.data.Dataset.from_tensor_slices(y_train)\n",
    "train_dataset = tf.data.Dataset.zip((X_train_idx_dataset, y_train_dataset))\n",
    "\n",
    "X_val_idx_dataset = tf.data.Dataset.from_tensor_slices(X_val_idx)\n",
    "y_val_dataset = tf.data.Dataset.from_tensor_slices(y_val)\n",
    "val_dataset = tf.data.Dataset.zip((X_val_idx_dataset, y_val_dataset))\n",
    "\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "val_dataset   = val_dataset.batch(batch_size)\n",
    "\n",
    "train_dataset = train_dataset.cache().prefetch(AUTOTUNE)\n",
    "val_dataset   = val_dataset.cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_batch shape: (128, 20)\n",
      "y_batch shape: (128,)\n"
     ]
    }
   ],
   "source": [
    "for x_batch, y_batch in train_dataset.take(1):\n",
    "    print(f\"x_batch shape: {x_batch.shape}\")\n",
    "    print(f\"y_batch shape: {y_batch.shape}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a bidirectional LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedding = False # fix embedding during training\n",
    "hidden_dim1 = 64\n",
    "hidden_dim2 = 64\n",
    "dp_rate = 0.5\n",
    "lr = 0.001\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "EztIWqCmlZof"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 20, 250)           13944750  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 250)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 20, 128)           161280    \n",
      "_________________________________________________________________\n",
      "layer_normalization (LayerNo (None, 20, 128)           40        \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "layer_normalization_1 (Layer (None, 128)               256       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 14,205,271\n",
      "Trainable params: 260,521\n",
      "Non-trainable params: 13,944,750\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = buildModel(embedding, train_embedding, sen_len, hidden_dim1, hidden_dim2, dp_rate, lr)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = os.path.join(path_prefix, 'ckpt/')\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, \n",
    "                  validation_data=val_dataset, \n",
    "                  epochs = epochs, \n",
    "                  callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method2 - with Kerastuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 9fb96e5fae6ca8f956829c8ec70c26ab</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7615333199501038</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dp: 0.6396740639549805</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-lr: 0.004125678102025594</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-lstm1: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-lstm2: 160</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(*args, **kwargs):\n",
    "        IPython.display.clear_output(wait = True)\n",
    "    \n",
    "tuner = RandomSearch(\n",
    "    BiLstmTuner(embedding, train_embedding, sen_len),\n",
    "    objective='val_accuracy',\n",
    "    max_trials = 10,\n",
    "    executions_per_trial = 3,\n",
    "    directory = os.path.join(path_prefix, 'tuner_dir'),\n",
    "    project_name = 'tsc')\n",
    "\n",
    "tuner.search(train_dataset,\n",
    "             epochs = 5,\n",
    "             validation_data = val_dataset,\n",
    "             verbose = 0,\n",
    "             callbacks = [ClearTrainingOutput()],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFvjFQopxVrt"
   },
   "outputs": [],
   "source": [
    "print('\\nload model ...')\n",
    "best_model = tf.keras.models.load_model(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 20, 250)           13944750  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 250)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 20, 192)           266496    \n",
      "_________________________________________________________________\n",
      "layer_normalization (LayerNo (None, 20, 192)           40        \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 384)               591360    \n",
      "_________________________________________________________________\n",
      "layer_normalization_1 (Layer (None, 384)               768       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 385       \n",
      "=================================================================\n",
      "Total params: 14,803,799\n",
      "Trainable params: 859,049\n",
      "Non-trainable params: 13,944,750\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_model = tuner.get_best_models()[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best dp = 0.5504156686436646\n",
      "best lstm1 = 96\n",
      "best lstm2 = 192\n",
      "best lr = 0.0028506288262581062\n"
     ]
    }
   ],
   "source": [
    "best_hp = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "hyper_parameters = ['dp', 'lstm1', 'lstm2', 'lr']\n",
    "\n",
    "for hp in hyper_parameters:\n",
    "    print(f\"best {hp} = {best_hp.get(hp)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-supervised Learning \n",
    "We can further train the model using the training data without label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_semi_learning = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_no_label_idx = preprocessor.sentences_word2idx(train_x_no_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_label_dataset = tf.data.Dataset.from_tensor_slices(X_train_no_label_idx)\n",
    "train_no_label_dataset = train_no_label_dataset.batch(batch_size)\n",
    "train_no_label_dataset = train_no_label_dataset.cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_no_label = best_model.predict(train_no_label_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_train_no_label = tf.sigmoid(pred_train_no_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487477\n"
     ]
    }
   ],
   "source": [
    "X_high_conf_ind = []\n",
    "y_high_conf = []\n",
    "\n",
    "for i, prob in enumerate(pred_prob_train_no_label):\n",
    "    if prob > threshold_semi_learning:\n",
    "        X_high_conf_ind.append(X_train_no_label_idx[i])\n",
    "        y_high_conf.append(1)\n",
    "    elif prob < (1 - threshold_semi_learning):\n",
    "        X_high_conf_ind.append(X_train_no_label_idx[i])\n",
    "        y_high_conf.append(0)\n",
    "    \n",
    "print(len(X_high_conf_ind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine self-training data and training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total_train_idx = np.vstack((X_train_idx, np.array(X_high_conf_ind)))\n",
    "y_total_train = y_train + y_high_conf\n",
    "\n",
    "X_total_train_idx_dataset = tf.data.Dataset.from_tensor_slices(X_total_train_idx)\n",
    "y_total_train_dataset = tf.data.Dataset.from_tensor_slices(y_total_train)\n",
    "total_train_dataset = tf.data.Dataset.zip((X_total_train_idx_dataset, y_total_train_dataset))\n",
    "\n",
    "total_train_dataset = total_train_dataset.batch(batch_size)\n",
    "total_train_dataset = total_train_dataset.cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 20, 250)           13944750  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 20, 250)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 20, 192)           266496    \n",
      "_________________________________________________________________\n",
      "layer_normalization_6 (Layer (None, 20, 192)           40        \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 384)               591360    \n",
      "_________________________________________________________________\n",
      "layer_normalization_7 (Layer (None, 384)               768       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 385       \n",
      "=================================================================\n",
      "Total params: 14,803,799\n",
      "Trainable params: 859,049\n",
      "Non-trainable params: 13,944,750\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_dp = 0.5504156686436646\n",
    "best_lstm1 = 96\n",
    "best_lstm2 = 192\n",
    "best_lr = 0.0028506288262581062\n",
    "\n",
    "full_train_model = buildModel(embedding, train_embedding, sen_len, best_lstm1, best_lstm2, best_dp, best_lr)\n",
    "\n",
    "full_train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = full_train_model.fit(total_train_dataset, \n",
    "                               epochs = 10,\n",
    "                               verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - ETA: 0s - loss: 1.2303 - accuracy: 0.80 - ETA: 3s - loss: 1.2750 - accuracy: 0.79 - ETA: 4s - loss: 1.2813 - accuracy: 0.78 - ETA: 4s - loss: 1.2508 - accuracy: 0.78 - ETA: 4s - loss: 1.2010 - accuracy: 0.79 - ETA: 4s - loss: 1.1838 - accuracy: 0.79 - ETA: 4s - loss: 1.2008 - accuracy: 0.79 - ETA: 4s - loss: 1.2205 - accuracy: 0.78 - ETA: 4s - loss: 1.2090 - accuracy: 0.78 - ETA: 4s - loss: 1.2469 - accuracy: 0.77 - ETA: 4s - loss: 1.2434 - accuracy: 0.77 - ETA: 4s - loss: 1.2518 - accuracy: 0.77 - ETA: 4s - loss: 1.2337 - accuracy: 0.77 - ETA: 4s - loss: 1.2074 - accuracy: 0.78 - ETA: 4s - loss: 1.2215 - accuracy: 0.77 - ETA: 4s - loss: 1.2118 - accuracy: 0.77 - ETA: 4s - loss: 1.2080 - accuracy: 0.78 - ETA: 4s - loss: 1.2077 - accuracy: 0.78 - ETA: 4s - loss: 1.1992 - accuracy: 0.78 - ETA: 4s - loss: 1.2072 - accuracy: 0.78 - ETA: 4s - loss: 1.2199 - accuracy: 0.77 - ETA: 4s - loss: 1.2350 - accuracy: 0.77 - ETA: 4s - loss: 1.2271 - accuracy: 0.77 - ETA: 4s - loss: 1.2232 - accuracy: 0.77 - ETA: 3s - loss: 1.2239 - accuracy: 0.77 - ETA: 3s - loss: 1.2303 - accuracy: 0.77 - ETA: 3s - loss: 1.2369 - accuracy: 0.77 - ETA: 3s - loss: 1.2286 - accuracy: 0.77 - ETA: 3s - loss: 1.2230 - accuracy: 0.77 - ETA: 3s - loss: 1.2270 - accuracy: 0.77 - ETA: 3s - loss: 1.2307 - accuracy: 0.77 - ETA: 3s - loss: 1.2339 - accuracy: 0.77 - ETA: 3s - loss: 1.2331 - accuracy: 0.77 - ETA: 3s - loss: 1.2326 - accuracy: 0.77 - ETA: 3s - loss: 1.2345 - accuracy: 0.77 - ETA: 3s - loss: 1.2341 - accuracy: 0.77 - ETA: 3s - loss: 1.2382 - accuracy: 0.77 - ETA: 3s - loss: 1.2304 - accuracy: 0.77 - ETA: 2s - loss: 1.2293 - accuracy: 0.77 - ETA: 2s - loss: 1.2311 - accuracy: 0.77 - ETA: 2s - loss: 1.2282 - accuracy: 0.77 - ETA: 2s - loss: 1.2251 - accuracy: 0.77 - ETA: 2s - loss: 1.2256 - accuracy: 0.77 - ETA: 2s - loss: 1.2345 - accuracy: 0.77 - ETA: 2s - loss: 1.2336 - accuracy: 0.77 - ETA: 2s - loss: 1.2285 - accuracy: 0.77 - ETA: 2s - loss: 1.2285 - accuracy: 0.77 - ETA: 2s - loss: 1.2302 - accuracy: 0.77 - ETA: 2s - loss: 1.2303 - accuracy: 0.77 - ETA: 2s - loss: 1.2298 - accuracy: 0.77 - ETA: 2s - loss: 1.2293 - accuracy: 0.77 - ETA: 2s - loss: 1.2340 - accuracy: 0.77 - ETA: 1s - loss: 1.2363 - accuracy: 0.77 - ETA: 1s - loss: 1.2337 - accuracy: 0.77 - ETA: 1s - loss: 1.2354 - accuracy: 0.77 - ETA: 1s - loss: 1.2376 - accuracy: 0.77 - ETA: 1s - loss: 1.2376 - accuracy: 0.77 - ETA: 1s - loss: 1.2399 - accuracy: 0.77 - ETA: 1s - loss: 1.2414 - accuracy: 0.77 - ETA: 1s - loss: 1.2410 - accuracy: 0.77 - ETA: 1s - loss: 1.2436 - accuracy: 0.77 - ETA: 1s - loss: 1.2452 - accuracy: 0.77 - ETA: 1s - loss: 1.2441 - accuracy: 0.77 - ETA: 1s - loss: 1.2447 - accuracy: 0.77 - ETA: 1s - loss: 1.2450 - accuracy: 0.77 - ETA: 0s - loss: 1.2449 - accuracy: 0.77 - ETA: 0s - loss: 1.2476 - accuracy: 0.77 - ETA: 0s - loss: 1.2468 - accuracy: 0.77 - ETA: 0s - loss: 1.2454 - accuracy: 0.77 - ETA: 0s - loss: 1.2438 - accuracy: 0.77 - ETA: 0s - loss: 1.2451 - accuracy: 0.77 - ETA: 0s - loss: 1.2431 - accuracy: 0.77 - ETA: 0s - loss: 1.2439 - accuracy: 0.77 - ETA: 0s - loss: 1.2429 - accuracy: 0.77 - ETA: 0s - loss: 1.2420 - accuracy: 0.77 - ETA: 0s - loss: 1.2444 - accuracy: 0.77 - ETA: 0s - loss: 1.2419 - accuracy: 0.77 - ETA: 0s - loss: 1.2404 - accuracy: 0.77 - ETA: 0s - loss: 1.2404 - accuracy: 0.77 - 6s 37ms/step - loss: 1.2404 - accuracy: 0.7740\n",
      "loss = 1.2404394149780273\n",
      "accuracy = 0.7740499973297119\n"
     ]
    }
   ],
   "source": [
    "metrics = full_train_model.metrics_names\n",
    "results = full_train_model.evaluate(val_dataset)\n",
    "\n",
    "for key, val in zip(metrics, results):\n",
    "    print(f\"{key} = {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = full_train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_history = history.history['loss']\n",
    "acc_history = history.history['accuracy']\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, constrained_layout=True)\n",
    "\n",
    "ax[0].plot(loss_history)\n",
    "ax[0].set_title('loss history')\n",
    "ax[1].plot(acc_history)\n",
    "ax[1].set_title('accuracy history')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "vFvjFQopxVrt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading testing data ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"loading testing data ...\")\n",
    "X_test = load_testing_data(testing_data)\n",
    "X_test_idx = preprocessor.sentences_word2idx(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices(X_test_idx)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = testing(best_model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "vFvjFQopxVrt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save csv ...\n",
      "Finish Predicting\n"
     ]
    }
   ],
   "source": [
    "# Write the result to a CSV file\n",
    "tmp = pd.DataFrame({\"id\":[str(i) for i in range(len(X_test))],\"label\":outputs})\n",
    "print(\"save csv ...\")\n",
    "tmp.to_csv(os.path.join(path_prefix, 'predict.csv'), index=False)\n",
    "print(\"Finish Predicting\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW4_RNN.ipynb",
   "provenance": [
    {
     "file_id": "16d1Xox0OW-VNuxDn1pvy2UXFIPfieCb9",
     "timestamp": 1604814490480
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
